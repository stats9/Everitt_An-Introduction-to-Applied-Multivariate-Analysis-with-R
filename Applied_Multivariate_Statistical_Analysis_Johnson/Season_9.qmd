---
title: Excercises of Season 9
format: gfm
---


#### Ex. iv. 

9.4. Given $\rho$ and $\psi$ in Exercise 9.1 and an m = 1 factor model, calculate the reduced
correlation matrix $\tilde{\rho} = \rho - \psi$ and the principal factor solution for the loading matrix L.
Is the result consistent with the information in Exercise 9.1? Should it be?

###### Soloution

```{r}
#| warning: false


rho <- matrix(c(1, 0.63, 0.45, 0.63, 1, 
                .35, .45, .35, 1), 3, 3, byrow = T)
rho
psi <- diag(c(0.19, 0.51, 0.75), 3)
psi
L <- matrix(c(0.9, 0.7, 0.5), 3, 1)
ll <- L %*% t(L)

le <- eigen(rho)$values
ve <- eigen(rho)$vectors
ress <- rho - psi

all(ress - ll < 1e-10)

```


<br>

***
***
***


### EX. 9.6 




$$
\begin{aligned}
& \text{Verify the following matrix identities}\\
& a:\quad (I + L' \Psi^{-1} L)^{-1} L' \Psi^{-1} L = I - (I + L' \Psi^{-1} L)^{-1} \\
& \text{Hint: Premultiply both sides by} ~(I + L' \Psi^{-1}L).\\
& b: \quad  (LL' +  \Psi)^{-1} =  \Psi^{-1} -  \Psi^{-1}(I +  L'\Psi^{-1}L)^{-1}L'\Psi^{-1} \\
& \text{Hint: Postmultiply both sides by} ~ (LL' + \Psi) ~\text{and use (a)}. \\
& c: \quad L'(LL' + \Psi)^{-1}= (I+L'\Psi^{-1}L)^{-1}L'\Psi^{-l} \\
& \text{Hint: Postmultiply the result in (b) by L, use (a),} \\
& \text{and take the transpose, noting that.} \\
& (LL'+\psi)^{-l},\psi^{−l}, \\
& \text{and} ~~ (I+L'\psi^{−l}) \\
& \text{are symmetric matrices.}\\
\end{aligned}
$$






#### Soloution 





a: 

$$
\begin{aligned}
& (I + L'\Psi^{-1}L) \times (I + L'\Psi^{-1}L)^{-1}L'\Psi^{-1}L = \\
& L'\Psi^{-1} L, \quad (I + L'\Psi^{-1}L) \times (I - (I + L'\Psi^{-1}L)^{-1}) = \\
& (I + L'\Psi^{-1}L) - I = L'\Psi^{-1}L
\end{aligned}
$$






b: 

$$
\begin{aligned}
& (LL' + \Psi)^{-1} \times (LL' + \Psi)   = I \implies \\
& (\Psi^{-1} -  \Psi^{-1}(I +  L'\Psi^{-1}L)^{-1}L'\Psi^{-1})\times (LL' + \Psi) = \\ 
& (\Psi^{-1} - \Psi^{-1}L(I + L'\Psi^{-1}L)^{-1}L'\Psi^{-1}) (LL'+ \Psi) = \\
& \Psi^{-1}(LL' + \Psi) - \Psi^{-1} \underset{\text{Using part a}}{\underbrace{L(I + L'\Psi^{-1}L)^{-1}L'\Psi^{-1}}}(LL'+\Psi) \\
& = \Psi^{-1}(LL'+\Psi) - \Psi^{-1}L(I - (I + L'\Psi^{-1}L)^{-1})L' \\
& = \Psi^{-1}L(I + L'\Psi^{-1}L)^{-1}L' = I
\end{aligned}
$$





Note: all these Muliplication steps are reversible






*c*: 

Muliplying the result in (b) by L we get 



$$
\begin{aligned}
& (LL' + \Psi)^{-1} L = \Psi^{-1} L - \Psi^{-1}L\underset{\text{Use part a}}{\underbrace{(I + L'\Psi^{-1}L)^{-1}L'\Psi^{-1}}} = \\
& = \Psi^{-1} L - \Psi^{-1} L(I - (I = L'\Psi^{-1}L)^{-1}) = \\
& \Psi^{-1}L(I + L'\Psi^{-1}L)^{-1}
\end{aligned}
$$





Result follows by taking the transpose of both sides of the
final equality. 




***
***
***


### EX. 9.8


9.8. (Unique but improper solution: Heywood case.)
Consider an m = 1 factor model for the population with covariance matrix

$$
\left[\begin{array}{ccc}
1 & 0.4 & 0.9 \\
0.4 & 1 & 0.7 \\
0.9 & 0.7 & 1
\end{array}\right]
$$

Show that there is a unique choice of $L$ and $\Psi$ with $\Sigma = L \times L^T + \Psi$, but that $\psi < 0$, 
so the choice is not admissible


###### Soloution: 

$$
\begin{aligned}
& \Sigma = LL' + \Psi \quad \text{for} ~m = 1 \implies \\
& \Sigma = \left[\begin{array}{ccc} 
1 = L_{11}^2 + \psi_1 & 0.4 = L_{11} \times L_{21} & 0.9 = L_{11} \times L_{31} \\
0.4 = L_{11} \times L_{21} &  1 = L_{21}^2 + \psi_2 & 0.7 = L_{21}\times L_{31} \\
0.9 = L_{11} \times L_{31} & 0.7 = L_{21}\times L_{31} & 1 = L_{31}^2 + \psi_3
\end{array}\right] \implies \\
& \text{We Have:}\quad \frac{L_{11}}{L_{21}} = \frac{0.9}{0.7} ~\text{and}~L_{11} \times L_{21} = 0.4, ~ \text{So} \quad \\
& L_{11}^2 = \frac{0.9}{0.7} \times 0.4 ~ \text{and} ~ L_{11} = \pm 0.717 \implies\\
& \text{Thus}\quad L_{21} = \pm 0.558, \quad \text{Finally}\\
& \text{from}\quad 0.9 = L_{11}\times L_{31} \implies \\
& \text{We Have:}\quad L_{31} = \pm \frac{0.9}{0.717} = \pm 1.255
\end{aligned}
$$

Note all the loadings must be of the same sign because all the covariances are positive. We have 

$$
\begin{aligned}
& L\times L^T = \left[\begin{array}{c} 0.717 \\ 0.558 \\ 1.255\end{array}\right] \times \left[\begin{array}{r}0.717 & 0.558 & 1.255\end{array}\right] = \\
& \left[\begin{array}{ccc} 0.514 & 0.4 & 0.9 \\ 0.4 & 0.3111 & 0.7 \\
0.9 & 0.7 & 1.575 \end{array}\right] \implies \\
& \text{So} \quad \psi_3 = 1  - 1.575 = -0.575 < 0 \text{which is inadmissible as a variance.}
\end{aligned}
$$



***
***
***



### EX 9.12. 

```{r}
dat = read.table('./Johnson_Data/table_9_12.txt', 
    header = TRUE, row.names = NULL)

names(dat) = c(
    'SalesGrowth', 
    'SalesProfitability', 
    'NewAccountSales', 
    'CreativityTest', 
    'MechanicalReasoningTest', 
    'AbstractReasoningTest', 
    'MathematicsTest'
)
dat[, 1] <- as.numeric(dat[, 1])
dim(dat)
head(dat)

```

#### (a)

```{r}
any(is.na(dat))
dat_scale <- sapply(dat, FUN = function(x) (x - mean(x))/sd(x))

# install.packages('psych')
library(psych)
KMO(cor(dat_scale))
cortest.bartlett(R = cor(dat_scale), n = 50)
```


```{r}
FaModel1 <- factanal(dat_scale, factors = 2, 
    method = "mle", rotation = 'none')
FaModel2 <- factanal(dat_scale, factors = 3, 
    method = 'mle', rotation = 'none')

```

```{r}
FaModel1
```


```{r}

FaModel2
```


#### (b) 

```{r}
FaModel_rotate_1 <- factanal(dat_scale, factors = 2, 
    method = "mle", rotation = "varimax")
FaModel_rotate_2 <- factanal(dat_scale, factors = 3, 
    method = 'mle', rotation = 'varimax')
```

```{r}
FaModel_rotate_1$loadings[]
FaModel_rotate_2$loadings[]

```


#### (c)


```{r}
LModel1 <- FaModel_rotate_1$loadings[]
LModel2 <- FaModel_rotate_2$loadings[]
communalities1 <- rowSums(LModel1^2)
communalities2 <- rowSums(LModel2^2)
communalities1
communalities2
```


```{r}
specific_variances1 <- 1 - communalities1
specific_variances2 <- 1 - communalities2
specific_variances1
specific_variances2

```


#### (d)

```{r}
n = 50
p = 7
m1 = 2
m2 = 3
(Psi1 <- diag(specific_variances1))
(Psi2 <- diag(specific_variances2))
(LL1 <- LModel1 %*% t(LModel1))
(LL2 <- LModel2 %*% t(LModel2))
(sig_estimate_1 <- Psi1 + LL1)
(sig_estimate_2 <- Psi2 + LL2)

(Sig_sample <- cov(dat_scale))

(c1 <- (n - 1 - (2 * p + 4*m1 + 5)/6))
(c2 <- (n - 1 - (2 * p + 4*m2 + 5)/6))

(det_ratio1 <- det(sig_estimate_1)/det(Sig_sample))
(det_ratio2 <- det(sig_estimate_2)/det(Sig_sample))

(chiModel1 <- c1 * log(det_ratio1))
(chiModel2 <- c2 * log(det_ratio2))

(df1 <- ((p - m1)^2 -p -m1)/2)
(df2 <- ((p - m2)^2 -p -m2)/2)


ifelse(chiModel1 > qchisq(0.01, df = df1, lower.tail = FALSE), "H0 for Model 1 Rejected", "H0 for Model 1 Accepted")
ifelse(chiModel2 > qchisq(0.01, df = df2, lower.tail = FALSE), "H0 for Model 2 Rejected", "H0 for Model 2 Accepted")
```




#### (e) 


```{r}
x <- c(110, 98, 105, 15, 18, 12, 35)

(SD <- sapply(dat, function(x) sd(x)))
(Means <- colMeans(dat))
(zj <- (x - Means)/SD)

# Weighted Least square
fModel1 <- solve(t(LModel1) %*% solve(Psi1) %*% LModel1) %*% 
    t(LModel1) %*% solve(Psi1) %*% zj
fModel1

fModel2 <- solve(t(LModel2) %*% solve(Psi2) %*% LModel2) %*% 
    t(LModel2) %*% solve(Psi2) %*% zj
fModel2


```


```{r}
fModel1_reg <- t(LModel1) %*% solve(Sig_sample) %*% zj
fModel2_reg <- t(LModel2) %*% solve(Sig_sample) %*% zj
fModel1_reg
fModel2_reg

```

***
***
***


### EX 9.21. 

Perform a varimax rotation of both m = 2 solutions in Exercise 9.20. Interpret the re-
sults. Are the principal component and maximum likelihood solutions consistent with
each other?



#### Soloution 



```{r}
dat <- read.table(file = "Johnson_Data/table_1_5.txt", header = FALSE)
names(dat) <- c("Wind", 
            "Solar radiation", 
            "CO", 
            "NO", 
            "NO2", 
            "o3", 
            "HC")
head(dat)

# install.packages("psych")
library(psych)

maModel <- fa(dat, nfactors = 2, 
            rotate = "varimax", fm = "ml")


paModel <- fa(dat, nfactors = 2, 
            rotate = "varimax", fm = "pa")
summary(maModel)
maModel$loadings[]
summary(paModel)
paModel$loadings[]
fa.diagram(maModel)
fa.diagram(paModel)
```



***
***
***



### EX 9.21. 

9.22. Refer to Exercise 9.20.
(a) Calculate the factor scores from the m = 2 maximum likelihood estimates by
(i) weighted least squares in (9-50) and (ii) the regression approach of (9-58).
(b) Find the factor scores from the principal component solution, using (9-51).
(c) Compare the three sets of factor scores.



#### Soloution


```{r}
#| warning: false
#| fig-height: 12
#| fig-width: 12

dataa <- read.table("Johnson_Data/table_1_5.txt", header = FALSE)
names(dataa) <- c("Wind", "Solar radiation", 
                "CO", "NO", "NO2", "o3", "HC")
head(dataa)

# Section (a): 1

# install.packages("psych")
library(psych)

# install.packages("GPArotation")
WssModel <- fa(dataa, nfactors = 2, fm = "ml", scores = "Bartlett")

WssModel
summary(WssModel)

WssModel$loadings[]


# section(a): 2

##############
WssModel2 <- fa(dataa, nfactors = 2, fm = "ml", scores = "Thurstone")

WssModel2
summary(WssModel2)

WssModel2$loadings[]




# section(c): 

WssModel3 <- fa(dataa, nfactors = 2, fm = "pa")

WssModel3
summary(WssModel3)

WssModel3$loadings[]
```