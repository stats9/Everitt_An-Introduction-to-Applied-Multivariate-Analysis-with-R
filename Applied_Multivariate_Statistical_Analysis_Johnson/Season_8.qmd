---
title: Excercises of Season 8 (Applied Multivariate Statistical Analysis Johnson)
format: gfm
---




```{r}
#| include: false

options(digits = 4)

```

***
***

<br><br> 

### Ex. xi. 

8.11. Consider the census-tract data listed in Table 8.5. Suppose the observations on X~5~ = median value home were recorded in ten thousands, rather than hundred thousands, of dollars; that is, multiply all the numbers listed in the sixth column of the table by 10.
(a) Construct the sample covariance matrix S for the census-tract data when
X~5~ = median value home is recorded in ten thousands of dollars. (Note that this.
covariance matrix can be obtained from the covariance matrix given in Example 8.3
by multiplying the off-diagonal elements in the fifth column and row by 10 and the
diagonal element s~55~ by 100. Why?)

(b) Obtain the eigenvalue-eigenvector pairs and the first two sample principal components for the covariance matrix in Part a.

(c) Compute the proportion of total variance explained by the first two principal
components obtained in Part b. Calculate the correlation coefficients, 
$r_{\hat{Y}_j, x_k}$, and
interpret these components if possible. Compare your results with the results in
Example 8.3. What. can you say about the effects of this change in scale on the
principal components?

<br><br>

##### Soloution: 


###### (a):

```{r}
#| warning: false

S <- matrix(c(3.397, -1.102, 4.306, -2.078, 0.027, 
            -1.102, 9.673, -1.513, 10.953, 1.203, 
            4.306, -1.513, 55.626, -28.937, -0.044, 
            -2.078, 10.953, -28.937, 89.067, 0.957, 
            0.027, 1.203, -0.044, 0.957, 0.319), 
            byrow = T, nrow = 5, ncol = 5)

S[, 5] <- 10 * S[, 5]
S[5, ] <- 10 * S[5, ]

print(S)
```


<br><br>

###### (b): 

```{r}
#| warning: false

E <- eigen(S)
la <- E$values
v <- E$vectors

la
v

```



$$
\begin{aligned}
& \hat{y}_1 = -0.038 x_1 + 0.119  x_2 - 0.480  x_3 + 0.859 x_4 + 0.129 x_5\\
& \hat{y}_2 = -0.062 x_1 - 0.249 x_2 - 0.759 x_3 - 0.316 x_4 - 0.508 x_5
\end{aligned}
$$



<br><br>


###### (c): 

```{r}
#| warning: false


cor_mat <- matrix(0, nrow = 2, ncol = 5)

for (i in 1:2) { 
    for (j in 1: 5) {
        temp <- v[, i]
        cor_mat[i, j] <- sqrt(la[i]) * temp[j] / sqrt(S[j, j])
    }
}
cor_mat
```


<br><br>

```{r}
#| warning: false

cumsum(la) / sum(la)
```


<br>

***
***

<br>

### Ex. xiii.

8.13. In the radiotherapy data listed in Table 1.7 (see also the radiotherapy data), the n = 98 observations on p = 6 variables rep-
resent patients' reactions to radiotherapy.
(a) Obtain the covariance and correlation matrices S and R for these data.
(b) Pick one of the matrices S or R (justify your choice), and determine the eigenval-
ues and eigenvectors. Prepare a table showing, in decreasing order of size, the per-
cent that each eigenvalue contributes to the total sample variance.
(c) Given the results in Part b, decide on the number of important sample principal
components. Is it possible to summarize the radiotherapy data with a single reaction-
index component? Explain.
(d) Prepare a table of the correlation coefficients between each principal component
you decide to retain and the original variables. If possible, interpret the components.

<br><br>

#### Soloution: 

###### load data 

```{r}
#| warning: false

dat <- read.table("Johnson_Data/table_1_7.txt", header = FALSE)

names(dat) <- paste("x", 1:6, sep = "_")
head(dat)
head(dat)


```


###### (a): 

```{r}
#| warning: false

R <- cor(dat)
S <- cov(dat)


print(R)

print(S)
```



***


###### (b): 


```{r}
Sigg <- diag(S)
print(Sigg)
```



As we can see, the variance values ​​of the variables in the data set are not very harmonious, four of the variables have variances less than one and one of them has a variance greater than four, so we use the S matrix to implement a principal components model.


```{r}
Es <- eigen(S)$values
ER <- eigen(R)$values

## Eigen values
print(Es)
print(ER)


## Eigen Vectors 
Vs <- eigen(S)$vectors
print(Vs)

VR <- eigen(R)$vectors
print(VR)

## sort eigenvalues 

Es1 <- sort(Es, decreasing = T)
Er1 <- sort(ER, decreasing = T)

## Table for EigenValues of Covariance Matrix 
round((Es1 / sum(Es1) * 100) , 4)


## table for EigenValues of Correlation Matrix
round((Er1 / sum(Er1) * 100) , 4)
round((cumsum(Er1) / sum(Er1) * 100) , 4)
abs(diff(Er1))


```




***
***



$$
r_{\hat{y}_i, ~ x_k} = \frac{\hat{e}_{k, i} \times \sqrt{\hat{\lambda}_i}}{\sqrt{s_{kk}}} \implies 
$$

```{r}
#| warning: false

mat_cor <- matrix(NA, 4, 6, dimnames = list(Pri = paste("y", 1:4, sep = ""), Var = paste("x", 1:6, sep = "")))

for (i in 1:4) {
    e <- Vs[, i]
    l <- Es[i]
    for (j in 1:6) {
        skk <- Sigg[j]
        mat_cor[i, j] = e[j] * sqrt(l) / sqrt(skk)
    }
}

round(mat_cor, 4)
```




***
***



#### EX. xvi. 

Over a period of five years in the 1990s, yearly samples of fishermen on 28 lakes in
Wisconsin were asked to report the time they spent fishing and how many of each
type of game fish they caught. Their responses were then converted to a catch rate per
hour for
x1 = Bluegill
x2 = Black crappie,  x3 = Smallmouth bass
x4 = Largemouth bass,  x5 = Walleye
x6 = Northern pike
The estimated correlation matrix (courtesy of Jodi Barnet)

$$
R = \begin{bmatrix}
1 & 0.4919 & 0.2636 & 0.4653 & -0.2277 & 0.0652 \\
0.4919 & 1 & 0.3127 & 0.3506 & -0.1917 & 0.2045 \\
0.2635 & 0.3127 & 1 & 0.4108 & -0.0647 & 0.2493 \\
0.4653 & 0.3506 & 0.4108 & 1 & -0.2249 & 0.2293 \\
-0.2277 & -0.1917 & -0.0647 & -0.2249 & 1 & -0.2144 \\
0.0652 & 0.2045 & 0.2493 & 0.2293 & -0.2144 & 1 \\
\end{bmatrix}
$$

is based on a sample of about 120. (There were a few missing values)
Fish caught by the same fisherman live alongside of each other, so the data should
provide some evidence on how the fish group. The first four fish belong to the centrar-
chids, the most plentiful family. The walleye is the most popular fish to eat.

(a) Comment on the pattern of correlation within the centrarchid family x1 through x4.
Does the walleye appear to group with the other fish?

(b) Perform a principal component analysis using only x1 through x4. Interpret your
results.

(c) Perform a principal component analysis using all six variables. Interpret your results.


##### Soloution 

(a): Considering that the correlation of the fifth variable with the first, second and fourth variables is negative and insignificant with the third variable, the fifth variable cannot be considered the same group as the first to fourth variables.


(b): 

```{r}
corr <- c(1, 0.491, 0.2636, 0.4653, -.2277, 0.0652, 
0.4919, 1, 0.3127, 0.3506, -.1917, 0.2045, 
0.2635, 0.3127, 1, 0.4108, -.0647, 0.2493, 
0.4653, 0.3506, 0.4108, 1, -.2249, 0.2293, 
-.2277, -.1917, -.0647, -.2249, 1, -.2144, 
0.0652, 0.2045, 0.2493, 0.2293, -.2144, 1)

R <- matrix(corr, ncol = 6, nrow = 6, byrow = TRUE)
R

model1 <- princomp(covmat = R[1:4, 1:4])
print(model1)
summary(model1)
model1$loadings

```



(c) 


```{r}
model2 <- princomp(covmat = R)
print(model2)
summary(model2)
model2$loadings
```

***
***

#### EX. XXiv 

8.24. Refer to Example 8.10 and the data in Table 5.8, page 240. Add the variable x6 = regular
overtime hours whose values are (read across)

6187    7336    6988    6964    8425    6778    5922    7307
7679    8259    10954   9353    6291    4969    4825    6019
and redo Example 8.10.


##### Soloution 



```{r}
#| warning: false
#| fig-height: 9
#| fig-width: 9

options(digits = 5)


dat <- read.table(file = "Johnson_Data/table_5_8.txt", 
            header = FALSE) 
names(dat) <- paste0("x", 1:6)
head(dat)


S <- cov(dat)
S

model <- princomp(dat, cor = FALSE,
            score = TRUE)
model
summary(model)
model$loadings[]
slambda <- model$sdev
slambda
lambda2 <- slambda^2
Y <- model$scores
head(Y)
cc <- qchisq(0.95, df = 2)
cc
l1 <- lambda2[1]; 
l2 <- lambda2[2]
fun1 <- function(x) sqrt(l2 * (cc - x^2/l1))
fun2 <- function(x) - sqrt(l2 * (cc - x^2 / l1))

dat2 <- data.frame(x = Y[, 1], y = Y[, 2])
plot(y ~ x, data = dat2, pch = 16, col = "darkblue", 
        xlim = c(-5000, 5000), 
        ylim = c(-4000, 4000), asp = 2)
    curve(fun1, -sqrt(cc * l1), sqrt(cc * l1), add = TRUE, 
            lwd = 2, col = "red")
    curve(fun2, -sqrt(cc * l1), sqrt(cc * l1), add = TRUE, 
            lwd = 2, col = "red")
    
```


***
***


#### EX. xxv. 

8.25. Refer to the police overtime hours data in Example 8.10. Construct an alternate control
chart, based on the sum of squares dU^2^, to monitor the unexplained variation in the orig-
inal observations summarized by the additional principal components.


```{r}
#| warning: false

dat <- read.table("Johnson_Data/table_5_8.txt", header = F)
head(dat)
R <- cor(dat)

model <- princomp(dat, cor = TRUE, scores = TRUE)

summary(model)

Y <- model$loadings[]

Y <- model$scores

l <- eigen(R)$values

l2 <- l[3:6]
yy <- Y[, 3:6]
for (i in 4) {
    yy[, i] <- 1/sqrt(l2[i]) * yy[, i]
}
new_y <- apply(yy, 1, function(x) sum(x^2))

UCL <- qchisq(0.95, df = 4)

time <- 1:16


# library(httpgd); hgd(); hgd_browse()
plot(x = time, y = new_y, xlab = "Priods", ylab = "Tj", 
            main = "Control Chart", type = "o", 
                col = "darkblue", pch = 16, cex = 2, ylim = c(0, 10))
abline(h = UCL, lwd = 2, col = "red")
text(x = 5, y = UCL + 0.2, label = "UCL Bond", cex = 2)

```


***
***


### Ex. XXvii. 

8.27. The pulp and paper properties data is given in Table 7.7. Using the four paper variables,
BL (breaking length), EM (elastic modulus), SF (Stress at failure) and BS (burst
strength), perform a principal component analysis using the covariance matrix S and the
correlation matrix R. Your analysis should include the following:
(a) Determine the appropriate number of components to effectively summarize the
variability. Construct a scree plot to aid in your determination.

(b) Interpret the sample principal components.

(c) Do you think it it is possible to develop a "paper strength" index that effectively con-
tains the information in the four paper variables? Explain.

(d) Using the values for the first two principal components, plot the data in a two-
dimensional space with ŷ1 along the vertical axis and ŷ2 along the horizontal axis.
Identify any outliers in this data set.



##### Soloution 


###### (a): 


```{r}
#| warning: false

datt <- data.frame(
    Y1 = c(21.312, 21.206, 20.709, 19.542, 20.449, 
    20.841, 19.06, 18.597, 19.346, 18.72, 18.587, 19.813, 19.989, 
    19.116, 18.769, 18.708, 19.323, 17.433, 19.195, 19.436, 20.136, 
    16.74, 18.589, 19.422, 24.42, 25.288, 26.119, 23.113, 25.209, 
    25.444, 23.699, 24.303, 24.793, 23.438, 24.197, 24.741, 24.17, 
    24.174, 25.052, 23.846, 24.822, 25.2, 23.695, 24.941, 25.007, 
    21.183, 21.875, 22.095, 25.166, 24.56, 22.007, 21.115, 26.194, 
    25.674, 25.93, 21.39, 18.441, 16.441, 16.294, 20.289, 17.163, 
    20.289), 
    Y2 = c(7.039, 6.979, 6.779, 6.601, 6.795, 6.919, 6.447, 
    6.261, 6.572, 6.455, 6.295, 6.775, 6.737, 6.512, 6.335, 6.271, 
    6.55, 5.948, 6.213, 6.387, 6.725, 6.168, 6.531, 6.615, 7.874, 
    8.034, 8.222, 7.288, 7.955, 8.045, 7.593, 7.775, 8.123, 7.65, 
    7.794, 7.996, 7.766, 7.877, 8.287, 7.639, 8.041, 8.27, 7.46, 
    7.929, 8.081, 7.156, 7.336, 7.447, 7.913, 7.854, 8.259, 7.913, 
    8.454, 8.208, 8.1, 7.475, 6.652, 6.315, 6.572, 7.719, 7.086, 
    7.437), 
    Y3 = c(5.326, 5.237, 5.06, 4.479, 4.912, 5.108, 4.246, 
    4.032, 4.358, 4.072, 4.068, 4.604, 4.686, 4.299, 4.089, 3.978, 
    4.404, 3.486, 4.3, 4.404, 4.723, 3.201, 3.989, 4.382, 6.999, 
    7.406, 7.771, 6.329, 7.296, 7.477, 6.609, 6.861, 7.202, 6.457, 
    6.833, 7.152, 6.846, 6.826, 7.332, 6.615, 7.129, 7.356, 6.567, 
    7.286, 7.287, 5.388, 5.762, 5.79, 7.211, 7.02, 7.322, 6.557, 
    7.816, 7.534, 7.669, 5.294, 3.946, 2.997, 3.017, 4.866, 3.396, 
    4.859), 
    Y4 = c(0.932, 0.871, 0.742, 0.513, 0.577, 0.784, 0.358, 
    0.215, 0.432, 0.372, 0.239, 0.637, 0.779, 0.588, 0.47, 0.457, 
    0.588, 0.104, 0.405, 0.519, 0.652, 0.104, 0.336, 0.432, 1.73, 
    1.873, 1.946, 1.513, 1.792, 1.847, 1.482, 1.583, 1.703, 1.477, 
    1.583, 1.728, 1.615, 1.692, 1.773, 1.56, 1.721, 1.785, 1.543, 
    1.703, 1.787, 0.924, 1.068, 1.182, 1.813, 1.701, 1.169, 0.928, 
    2.145, 2.046, 2.037, 0.875, 0.14, -0.4, -0.478, 0.239, -0.236, 
    0.47))

dim(datt)
S <- cov(datt)

E <- eigen(S)
la <- E$values
v <- E$vectors
n <- length(la)
plot(x = 1:n, y = la, type = "l", main = "Scree Plot", 
        lwd = 2, col = "red")
cumsum(la) / sum(la)
```



<br>

###### (b): 


```{r}
Model <- princomp(datt, cor = TRUE, scores = TRUE)

Model

summary(Model)
```

```{r}

cor(datt)
```



<br>


###### (d): 


```{r}
#| warning: false

Y <- Model$scores
dim(Y)
y1 <- Y[, 1]
y2 <- Y[, 2]

plot(x = y1, y = y2, cex = 3, col = "red", pch = 16)
```